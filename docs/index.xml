<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bingz Learning Blog</title>
    <link>/</link>
    <description>Bingz Learning Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>bingwang8878@gamil.com (Bing Wang)</managingEditor>
    <webMaster>bingwang8878@gamil.com (Bing Wang)</webMaster>
    <lastBuildDate>Thu, 06 Jun 2024 22:04:53 -0700</lastBuildDate>
    
    <atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>bingwang8878@gamil.com (Bing Wang)</author>
      <guid>/about/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Welcome to Bingz Blog! ðŸ‘‹&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This is a space where we share our knowledge and experiences about &lt;strong&gt;Machine Learning&lt;/strong&gt; and &lt;strong&gt;Artificial Intelligence&lt;/strong&gt;. ðŸ’¡&lt;/p&gt;
&lt;p&gt;We hope you enjoy reading our posts and find them helpful and informative. ðŸ“– We&amp;rsquo;d Love to Hear From You! ðŸ“«&lt;/p&gt;
&lt;p&gt;If you have any questions or comments, please feel free to reach out to us. We would love to hear from you!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Causality Introduction</title>
      <link>/posts/2024-05-28-causality/</link>
      <pubDate>Tue, 28 May 2024 16:19:16 -0700</pubDate>
      <author>bingwang8878@gamil.com (Bing Wang)</author>
      <guid>/posts/2024-05-28-causality/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://bingzw.github.io/causality/causality_icon.png&#34; alt=&#34;causality_icon&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;what-is-causality&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#what-is-causality&#34;&gt;
        
    &lt;/a&gt;
    What Is Causality?
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;Different from common ML tasks that focus on summarizing the patterns in the data, expecting to make predictions on
similar unseen data. Causality, on the other hand, is about understanding the underlying mechanisms that drive the data.
It is about to predict how the people/agent/system would react if it were intervened in a certain way. Think about the
example of having two parallel universes with different light, temperature, and humidity conditions. What would happen
to a plant if it were moved from one universe to another? This is a causal question.&lt;/p&gt;
&lt;h3 id=&#34;causal-formulation&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#causal-formulation&#34;&gt;
        
    &lt;/a&gt;
    Causal Formulation
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;To understand how the outcome would change in different conditions, we need to define the following notations to
describe the causal relations.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Y_i$: the outcome of interest for individual $i$. For example, the health status of a patient.&lt;/li&gt;
&lt;li&gt;$A_i$: an indicator of whether the individual $i$ received the treatment. For example, a new drug.&lt;/li&gt;
&lt;li&gt;$X_i$: a set of covariates that may affect both the treatment assignment and the outcome. For example, health status,
age, gender etc&lt;/li&gt;
&lt;li&gt;$U_i$: unobserved factors that may affect both the treatment assignment and the outcome. For example, genetic factors.&lt;/li&gt;
&lt;li&gt;$Y_i^{a}$: the potential outcome of individual $i$ if he/she received the treatment $A = a, a \in \{0, 1\}$. For
example, the health status of a patient if he/she received the new drug ($a=1$).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In practice, the data $(Y_i, A_i, X_i)$ is usually drawn i.i.d from a population and they are formulated into a causal
graph as shown below&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
    &lt;img src=&#34;https://bingzw.github.io/causality/causal_model_diagram.png&#34; width=&#34;600&#34; height=&#34;400&#34;&gt;&lt;br&gt;
    &lt;em&gt;Figure 1: causal inference elements&lt;/em&gt;
&lt;/p&gt;
&lt;p&gt;The mechanism of the causal graph is often reasoning by structural causal models (SCM). It models the underlying data
generation process with an ordered sequence of functions that map the parent nodes to the child nodes. For example, the
SCMs of the above causal graph can be written as:
$P(Y, A, X) = P(Y | A, X) P(X | A) P(A)$. This equation describes the probabilistic dependencies between the observed
variables. Now the question is how do we define the effect of the new drug $A$ on health outcome $Y$?&lt;/p&gt;
&lt;h3 id=&#34;average-treatment-effect&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#average-treatment-effect&#34;&gt;
        
    &lt;/a&gt;
    Average Treatment Effect
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Let&amp;rsquo;s continue with the above drug trail context and notations. Consider a simple case with a binary treatment $A$
(1: treated, 0: untreated) and a binary outcome $Y$ (1: recovered, 0: not recovered).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$Y^{a=1}$ (Y under the treatment
a = 1) be the outcome variable that would have been observed if the patient had received the treatment.&lt;/li&gt;
&lt;li&gt;$Y^{a=0}$ (Y
under the treatment a = 0) be the outcome variable that would have been observed if the patient had not received the
treatment.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;When estimating the causal effect on the &lt;strong&gt;population&lt;/strong&gt;, it&amp;rsquo;s usually to consider the average treatment effect (ATE),
$ATE = E[Y^{a=1}] - E[Y^{a=0}]$, denoting the average causal effect of the treatment on the outcome.&lt;/p&gt;
&lt;h2 id=&#34;causal-effect-estimation&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#causal-effect-estimation&#34;&gt;
        
    &lt;/a&gt;
    Causal Effect Estimation
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;With the causal formulation and the average treatment effect defined, the next step is to estimate the causal effect
from the observed data. Multiple methods have been developed for this purpose, each relying on different assumptions
and is suitable for different scenarios. Some of the most common methods include: &lt;em&gt;randomized controlled trials (A/B
testing)&lt;/em&gt;, &lt;em&gt;confounder adjustments methods&lt;/em&gt;, &lt;em&gt;instrumental variables&lt;/em&gt;, and &lt;em&gt;difference-in-differences&lt;/em&gt; etc.&lt;/p&gt;
&lt;h3 id=&#34;randomized-controlled-trials-ab-testing&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#randomized-controlled-trials-ab-testing&#34;&gt;
        
    &lt;/a&gt;
    Randomized Controlled Trials (A/B Testing)
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;The most common approach to estimate the causal effect is to run an experiment, usually in the following general steps.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Objective: Define the research question and the hypothesis (usually built with treatment metrics) to be tested.&lt;/li&gt;
&lt;li&gt;Design: Randomly assign the subjects into two groups, the treatment group (A) and the control group (B). The
treatment group receives the treatment, while the control group does not.&lt;/li&gt;
&lt;li&gt;Randomization: Randomly assign the subjects to the treatment and control groups to ensure the groups are comparable.&lt;/li&gt;
&lt;li&gt;Run test: Implement the A/B test and let it run for a sufficient period to gather an adequate amount of data&lt;/li&gt;
&lt;li&gt;Analysis: Analyze the data and calculate the treatment effect.&lt;/li&gt;
&lt;li&gt;Decisions: Make decisions based on the test results.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Randomized controlled trials are considered the gold standard for causal inference because they can eliminate the
confounding bias by randomizing the treatment assignment. However, they are not always feasible due to ethical,
practical, or financial reasons. Therefore, other methods are developed to estimate the causal effect from observational
data.&lt;/p&gt;
&lt;h3 id=&#34;causal-inference---confounder-adjustments-methods&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#causal-inference---confounder-adjustments-methods&#34;&gt;
        
    &lt;/a&gt;
    Causal Inference - Confounder Adjustments Methods
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;Before diving into the confounder adjustments methods, let&amp;rsquo;s first clarify the confounding bias. Consider the following
example:&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
    &lt;img src=&#34;https://bingzw.github.io/causality/confounder_selection_bias.png&#34;&gt;&lt;br&gt;
    &lt;em&gt;Figure 2: confounder example&lt;/em&gt;
&lt;/p&gt;
&lt;p&gt;A study is conducted to investigate the effect of a new drug on the health outcome of patients. The study
finds that patients who received the new drug have a higher recovery rate than those who did not. However, the study
also finds that the patients who received the new drug are younger and healthier than those who did not. Therefore, the
observed effect of the new drug on the health outcome may be &lt;strong&gt;confounded&lt;/strong&gt; by the age and health status of the patients.
To estimate the causal effect of the new drug on the health outcome, we need to &lt;em&gt;adjust&lt;/em&gt; for the confounding factors,
such as age and health status.&lt;/p&gt;
&lt;h4 id=&#34;key-assumptions&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#key-assumptions&#34;&gt;
        
    &lt;/a&gt;
    Key Assumptions
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;All the confounder adjustments methods rely on the following key assumptions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Exchangeability&lt;/strong&gt;: the treatment assignment is independent of the potential outcomes given the covariates.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Positivity&lt;/strong&gt;: the probability of receiving the treatment is positive for all levels of the covariates.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consistency&lt;/strong&gt;: the individual&amp;rsquo;s potential outcome is the same as the observed outcome when the treatment is received.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;general-flow-of-causal-inference&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#general-flow-of-causal-inference&#34;&gt;
        
    &lt;/a&gt;
    General Flow of Causal Inference
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;In general, causal inference is to build a pseudo-population that mimics the randomized experimentation from the observed
data. The assumptions taken and the modeling approaches applied are to ensure the pseudo-population is unbiased and
consistent with the true population. The general flow of causal inference can be summarized as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Define the Problem&lt;/strong&gt;: What are the causal effect of interest? What are the treatment and outcome variables?&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Acquire Data&lt;/strong&gt;: Collect the data that contains the treatment, outcome, and covariates.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Build the Causal Model&lt;/strong&gt;: Fit the causal model that describes the causal relationship&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Estimate the Causal Effect&lt;/strong&gt;: Estimate the counterfactual causal effect using the trained model&lt;/li&gt;
&lt;/ol&gt;
&lt;p align=&#34;center&#34;&gt;
    &lt;img src=&#34;https://bingzw.github.io/causality/causal_inference_flow.png&#34; width=&#34;800&#34; height=&#34;500&#34;&gt;&lt;br&gt;
    &lt;em&gt;Figure 3: Causal Inference Modeling Flow&lt;/em&gt;
&lt;/p&gt;
We follow the same modeling process in figure 3. First defining the outcome, treatment, and covariates, then building the
causal model using the sample data. Next to estimate the counterfactual performance for both treated and untreated in the
treatment and control groups. The dashed figure in the above graph represents the unobserved counterfactuals that are 
estimated from the counterfactual model. Finally, the causal effect is then estimated by comparing the observed outcome 
with the estimated counterfactual outcome.
&lt;p&gt;Let&amp;rsquo;s dive deep into how the causal model&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; can be trained from the observed data.&lt;/p&gt;
&lt;h4 id=&#34;inverse-probability-weighting&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#inverse-probability-weighting&#34;&gt;
        
    &lt;/a&gt;
    Inverse Probability Weighting
&lt;/div&gt;
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Key Idea: Assigning weights to observations in order to create a pseudo-population that approximates the population
that would have been obtained through random assignment in a randomized control trial (RCT).&lt;/li&gt;
&lt;li&gt;Steps:
&lt;ol&gt;
&lt;li&gt;Estimate the propensity score, $g(x) = P(A = 1 | X = x)$, the probability of receiving the treatment given the
covariates.&lt;/li&gt;
&lt;li&gt;Calculate the inverse probability weights, $w_i = \frac{P(A_i)}{g(x_i)}$.&lt;/li&gt;
&lt;li&gt;Fit a marginal structure model $E[Y^a] = \beta_0 + \beta_1 a$ with the inverse probability weights $w_i$.&lt;/li&gt;
&lt;li&gt;Estimate the average treatment effect, $ATE = \hat{\beta_1}$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;standardization&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#standardization&#34;&gt;
        
    &lt;/a&gt;
    Standardization
&lt;/div&gt;
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Key Idea: Standardize the outcome under different treatment conditions to estimate the average treatment effect.&lt;/li&gt;
&lt;li&gt;Steps:
&lt;ol&gt;
&lt;li&gt;Fit the outcome model with treatment and covariates, $P[Y^a | X=x] = P(Y | A=a, X=x)$. For example, the linear model
representation is $Y^A = \beta_0 + \beta_1 A + \beta_2 X + \epsilon$.&lt;/li&gt;
&lt;li&gt;Estimate the expectation of the outcome under different treatment conditions:
$E[Y^a] = \int_x P(Y|A=a, x)*f_X(x)dx$.&lt;/li&gt;
&lt;li&gt;Calculate the average treatment effect, $ATE = E[Y^{a=1}] - E[Y^{a=0}]$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;stratification&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#stratification&#34;&gt;
        
    &lt;/a&gt;
    Stratification
&lt;/div&gt;
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Key Idea: Stratify the data into different strata based on the covariates and estimate the average treatment effect.&lt;/li&gt;
&lt;li&gt;Steps:
&lt;ol&gt;
&lt;li&gt;Estimate the propensity score, $g(x) = P(A = 1 | X = x)$, the probability of receiving the treatment given the
covariates.&lt;/li&gt;
&lt;li&gt;Fit the outcome model with treatment and propensity score as the covariates,
$P[Y^a | X=x] = P(Y | A=a, g(x))$. A simple linear representation is $Y^A = \beta_0 + \beta_1 A + \beta_2 * g(X) + \epsilon$.&lt;/li&gt;
&lt;li&gt;Estimate the expectation of the outcome under different treatment conditions:
$E[Y^a] = \int_x P(Y|A=a, g(x))*f_X(x)dx$&lt;/li&gt;
&lt;li&gt;Calculate the average treatment effect, $ATE = E[Y^{a=1}] - E[Y^{a=0}]$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;propensity-score-matching&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#propensity-score-matching&#34;&gt;
        
    &lt;/a&gt;
    Propensity Score Matching
&lt;/div&gt;
&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Key Idea: Match the treated and control units based on the propensity score to estimate the average treatment effect.&lt;/li&gt;
&lt;li&gt;Steps:
&lt;ol&gt;
&lt;li&gt;Estimate the propensity score, $g(x) = P(A = 1 | X = x)$, the probability of receiving the treatment given the
covariates.&lt;/li&gt;
&lt;li&gt;Match the treated and control units based on the propensity score. (Nearest Neighbour, Kernel Matching, etc)&lt;/li&gt;
&lt;li&gt;Estimate the average treatment effect, $ATE = E[Y^{a=1}] - E[Y^{a=0}]$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;double-machine-learning-dml&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#double-machine-learning-dml&#34;&gt;
        
    &lt;/a&gt;
    Double Machine Learning (DML)
&lt;/div&gt;
&lt;/h4&gt;
&lt;p&gt;In all above methods, we have observed that two components are needed to estimate the causal effect: the propensity score
$g(x) = P(A = 1 | X = x)$ and the outcome model $P[Y^a | X=x] = P(Y | A=a, X=x)$. However, the estimation of these
components may be biased, leading to biased estimates of the causal effect. To address this issue, double machine learning
(DML) is proposed.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Key Idea: Use machine learning algorithms to estimate the nuisance functions and statistical estimation techniques to
estimate the causal effect.&lt;/li&gt;
&lt;li&gt;Steps:
&lt;ol&gt;
&lt;li&gt;Divide the data into K-folds (cross fitting). For each fold $i$, train the propensity score model and the outcome model on
folds other than $i$, i.e. $g^{-i}(x)$ and $P^{-i}(Y^a | X)$.&lt;/li&gt;
&lt;li&gt;Estimating the augmented inverse probability of treatment weighted estimator (AIPTW) for fold $i$:
$\hat{\tau_i} = \frac{1}{n_i} \sum_{i} \hat{P}^{-i}(Y^{a=1} | x_i) - \hat{P}^{-i}(Y^{a=0} | x_i) + A_i\frac{Y_i - \hat{P}^{-i}(Y^{a=1} | x_i)}{\hat{g}^{-i}(x_i)} - (1-A_i)\frac{Y_i - \hat{P}^{-i}(Y^{a=0} | x_i)}{1-\hat{g}^{-i}(x_i)}$&lt;/li&gt;
&lt;li&gt;Aggreagate the estimates from all folds to get the final estimate of the causal effect, $\hat{\tau} = \frac{1}{N} \sum_{i} n_i \hat{\tau_i}$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;causal-inference---instrumental-variables&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#causal-inference---instrumental-variables&#34;&gt;
        
    &lt;/a&gt;
    Causal Inference - Instrumental Variables
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;All above approaches rely on the assumption of no unobserved confounding, which may not be satisfied in practice. When
there is potential endogeneity or unobserved confounding in observational data, instrumental variables can be used to
estimate the causal effect.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Key Idea: Estimating the causal effect of a treatment or intervention when there is potential endogeneity or
unobserved confounding in observational data. It relies on the use of an instrumental variable, which is a variable
that is correlated with the treatment but not directly with the outcome, except through its influence on the treatment.&lt;/li&gt;
&lt;li&gt;Assumptions:
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Relevance&lt;/strong&gt;: the instrumental variable is correlated with the treatment.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exogeneity&lt;/strong&gt;: the instrumental variable is independent of the unobserved confounders.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exclusion Restriction&lt;/strong&gt;: the instrumental variable affects the outcome only through the treatment.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;Steps:
&lt;ol&gt;
&lt;li&gt;Estimate the first-stage regression: $A = \alpha_0 + \alpha_1 Z + \epsilon_1$.&lt;/li&gt;
&lt;li&gt;Estimate the second-stage regression: $Y = \beta_0 + \beta_1 \hat{A} + \epsilon_2$.&lt;/li&gt;
&lt;li&gt;Calculate the average treatment effect, $ATE = \hat{\beta_1}$.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So far, we have discussed the major methods for estimating the causal effect from observational data. Each method has its
own assumptions and limitations, there is no clear winner and the choice of method depends on the specific context and
data characteristics. In practice, it is often recommended to use multiple methods to estimate the causal effect and
compare the results to ensure the robustness of the conclusions.&lt;/p&gt;
&lt;h2 id=&#34;root-cause-optimization&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#root-cause-optimization&#34;&gt;
        
    &lt;/a&gt;
    Root Cause Optimization
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;In the above sections, we designed a hypothetical causality problem of estimating the effect of taking a new drug. The
treatment variable $A$ can be defined as $A_i = 1$ if the patient takes the new drug and $A_i = 0$ if the patient does not.
More generally, the treatment variable can be formulated in this way $A = 1_{{f(\theta) &amp;lt; \mu}}$, where $f(\theta)$ is
the function that maps the treatment parameters $\theta$ to the treatment assignment, and $\mu$ is the threshold that
determines the treatment assignment. $f(\theta)$ is often a known metric since causal inference usually starts with some
suspected causal mechanisms. However, the threshold $\mu$ is often unknown and needs to be optimized to maximize the
causal effect. Therefore, the root cause optimization is to find the optimal threshold $\mu$ that maximizes the causal
effect.&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
$argmax_{\mu} E[Y^{A=1}] - E[Y^{A=0}]$, 
where $A = 1_{\{f(\theta) &lt; \mu\}}$ with given $f(\theta)$
&lt;p&gt;
&lt;p&gt;To solve the optimization problem, we can use the causal inference methods discussed above to estimate the causal effect
under different thresholds and find the optimal threshold that maximizes the causal effect. Popular optimization algorithms
such as grid search, random search and bayesian optimization can be used to find the optimal threshold.&lt;/p&gt;
&lt;h2 id=&#34;appendix&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#appendix&#34;&gt;
        
    &lt;/a&gt;
    Appendix
&lt;/div&gt;
&lt;/h2&gt;
&lt;h3 id=&#34;do-calculus&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#do-calculus&#34;&gt;
        
    &lt;/a&gt;
    Do Calculus
&lt;/div&gt;
&lt;/h3&gt;
&lt;p&gt;While we formulate the causal effect from the counterfactual perspective, there is another powerful tool that called
do-calculus that estimates the causal effect by setting interventions on the treatment variable. In particular, it&amp;rsquo;s
trying to apply interventions $A=a$ to the causal graph that deletes the edges pointing to $A$, and then conditioning on
the observed variables to estimate the causal effect. The average treatment effect can be written as:&lt;/p&gt;
&lt;p align=&#34;center&#34;&gt;
$ATE = E[Y^{a=1}] - E[Y^{a=0}] = E[Y|do(A=1)] - E[Y|do(A=0)]$
&lt;p&gt;
&lt;p&gt;Please refer to the do-calculus literature&lt;sup id=&#34;fnref:3&#34;&gt;&lt;a href=&#34;#fn:3&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;3&lt;/a&gt;&lt;/sup&gt; for more details.&lt;/p&gt;
&lt;h2 id=&#34;citation&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#citation&#34;&gt;
        
    &lt;/a&gt;
    Citation
&lt;/div&gt;
&lt;/h2&gt;
&lt;p&gt;If you find this post helpful, please consider citing it as:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bibtex&#34; data-lang=&#34;bibtex&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#f3f99d&#34;&gt;@article&lt;/span&gt;{&lt;span style=&#34;color:#ff5c57&#34;&gt;wang2024causality&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#57c7ff&#34;&gt;author&lt;/span&gt; = &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;Bing Wang&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#57c7ff&#34;&gt;title&lt;/span&gt; = &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;Causality Introduction&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#57c7ff&#34;&gt;journal&lt;/span&gt; = &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;bingzw.github.io&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#57c7ff&#34;&gt;year&lt;/span&gt; = &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;2024&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#57c7ff&#34;&gt;month&lt;/span&gt; = &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;May&amp;#34;&lt;/span&gt;,
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;  &lt;span style=&#34;color:#57c7ff&#34;&gt;url&lt;/span&gt; = &lt;span style=&#34;color:#5af78e&#34;&gt;&amp;#34;https://bingzw.github.io/posts/2024-05-28-causality/&amp;#34;&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;}
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;or&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#e2e4e5;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-markdown&#34; data-lang=&#34;markdown&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;Bing Wang. (2024, May). Causality Introduction. 
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;https://bingzw.github.io/posts/2024-05-28-causality/
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;reference&#34; &gt;
&lt;div&gt;
    &lt;a href=&#34;#reference&#34;&gt;
        
    &lt;/a&gt;
    Reference
&lt;/div&gt;
&lt;/h2&gt;
&lt;div class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Od6oAz1Op2k&#34;&gt;Causal Inference: Explained&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;
&lt;p&gt;&lt;a href=&#34;https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/&#34;&gt;HernÃ¡n MA, Robins JM (2020). Causal Inference: What If. Boca Raton: Chapman &amp;amp; Hall/CRC.&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;
&lt;p&gt;Pearl, Judea (2000). Causality: Models, Reasoning, and Inference.&amp;#160;&lt;a href=&#34;#fnref:3&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
