<!DOCTYPE html>


<html lang="en-us" data-theme="">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    
        
<meta charset="utf-8">
<meta name="HandheldFriendly" content="True">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="referrer" content="no-referrer-when-downgrade">

<title>A Journey to Reinforcement Learning - Bingz Learning Blog</title>

<meta name="description" content="An summary of reinforcement learning algorithms">





<link rel="icon" type="image/x-icon" href="http://localhost:1313/favicon.ico">
<link rel="apple-touch-icon-precomposed" href="http://localhost:1313/favicon.png">






    



    



<style>
  body {
    visibility: hidden;
    opacity: 0;
  }
</style>

<noscript>
  <style>
    body {
      visibility: visible;
      opacity: 1;
    }
  </style>
</noscript>




    





    
    
    

    
        <link rel="stylesheet" href="/css/style.03df79c682b91915c7cd261ecd1a6ec4d0fe668c98fa46310d0fbade319b11bd.css" integrity="sha256-A995xoK5GRXHzSYezRpuxND&#43;ZoyY&#43;kYxDQ&#43;63jGbEb0=">
    





    





    
    
    

    
        <link rel="stylesheet" href="/css/style.9c1888ebff42c0224ce04dac10cb2c401f1b77f54f78e8d87d73c3bed781c263.css" integrity="sha256-nBiI6/9CwCJM4E2sEMssQB8bd/VPeOjYfXPDvteBwmM=">
    





    





    
    
    

    
        <link rel="stylesheet" href="/css/style.acd606c0fce58853afe0248d37bb41acbbcdd8b1aca2412b6c0fa760da0137f3.css" integrity="sha256-rNYGwPzliFOv4CSNN7tBrLvN2LGsokErbA&#43;nYNoBN/M=">
    












    

    





    
    
    

    
        <script src="/js/script.672e2309c296e07c18bcd08b28d797a56222ff941d65f308fba3158c44885b14.js" type="text/javascript" charset="utf-8" integrity="sha256-Zy4jCcKW4HwYvNCLKNeXpWIi/5QdZfMI&#43;6MVjESIWxQ="></script>
    



















    
</head>
<body>
    <a class="skip-main" href="#main">Skip to main content</a>
    <div class="container">
        <header class="common-header">
            
                <div class="header-top">
    <div class="header-top-left">
        <h1 class="site-title noselect">
    <a href="/">Bingz Learning Blog</a>
</h1>

        



    



    



    
        <div class="theme-switcher">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-sun-high"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M14.828 14.828a4 4 0 1 0 -5.656 -5.656a4 4 0 0 0 5.656 5.656z" /><path d="M6.343 17.657l-1.414 1.414" /><path d="M6.343 6.343l-1.414 -1.414" /><path d="M17.657 6.343l1.414 -1.414" /><path d="M17.657 17.657l1.414 1.414" /><path d="M4 12h-2" /><path d="M12 4v-2" /><path d="M20 12h2" /><path d="M12 20v2" /></svg>


</span>

        </div>
    

    <script>
        const STORAGE_KEY = 'user-color-scheme'
        const defaultTheme = "auto"

        let currentTheme
        let switchButton
        let autoDefinedScheme = window.matchMedia('(prefers-color-scheme: dark)')

        function switchTheme(e) {
            currentTheme = (currentTheme === 'dark') ? 'light' : 'dark';
            if (localStorage) localStorage.setItem(STORAGE_KEY, currentTheme);
            document.documentElement.setAttribute('data-theme', currentTheme);
            changeGiscusTheme(currentTheme);
            document.body.dispatchEvent(new CustomEvent(currentTheme + "-theme-set"));
        }

        const autoChangeScheme = e => {
            currentTheme = e.matches ? 'dark' : 'light'
            document.documentElement.setAttribute('data-theme', currentTheme);
            changeGiscusTheme(currentTheme);
            document.body.dispatchEvent(new CustomEvent(currentTheme + "-theme-set"));
        }

        document.addEventListener('DOMContentLoaded', function () {
            switchButton = document.querySelector('.theme-switcher')
            currentTheme = detectCurrentScheme()

            if (currentTheme === 'auto') {
                autoChangeScheme(autoDefinedScheme);
                autoDefinedScheme.addListener(autoChangeScheme);
            } else {
                document.documentElement.setAttribute('data-theme', currentTheme)
            }

            if (switchButton) {
                switchButton.addEventListener('click', switchTheme, false)
            }

            showContent();
        })

        function detectCurrentScheme() {
            if (localStorage !== null && localStorage.getItem(STORAGE_KEY)) {
                return localStorage.getItem(STORAGE_KEY)
            }
            if (defaultTheme) {
                return defaultTheme
            }
            return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
        }

        function showContent() {
            document.body.style.visibility = 'visible';
            document.body.style.opacity = 1;
        }

        function changeGiscusTheme (theme) {
            function sendMessage(message) {
              const iframe = document.querySelector('iframe.giscus-frame');
              if (!iframe) return;
              iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
            }

            sendMessage({
              setConfig: {
                theme: theme
              }
            });
        }
    </script>


        <ul class="social-icons noselect">


    
        
        
        <li>
            <a href="https://github.com/bingzw" title="Github" rel="me">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-brand-github"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4 -4.3 -2.5 -6 -3m12 5v-3.5c0 -1 .1 -1.4 -.5 -2c2.8 -.3 5.5 -1.4 5.5 -6a4.6 4.6 0 0 0 -1.3 -3.2a4.2 4.2 0 0 0 -.1 -3.2s-1.1 -.3 -3.5 1.3a12.3 12.3 0 0 0 -6.2 0c-2.4 -1.6 -3.5 -1.3 -3.5 -1.3a4.2 4.2 0 0 0 -.1 3.2a4.6 4.6 0 0 0 -1.3 3.2c0 4.6 2.7 5.7 5.5 6c-.6 .6 -.6 1.2 -.5 2v3.5" /></svg>


</span>

            </a>
        </li>
    

    
        <li>
            <a href="https://www.linkedin.com/in/bingzw/" title="Linkedin" rel="me">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-brand-linkedin"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 4m0 2a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v12a2 2 0 0 1 -2 2h-12a2 2 0 0 1 -2 -2z" /><path d="M8 11l0 5" /><path d="M8 8l0 .01" /><path d="M12 16l0 -5" /><path d="M16 16v-3a2 2 0 0 0 -4 0" /></svg>


</span>

            </a>
        </li>
    






    <li>
            <a href="/index.xml" title="RSS" rel="me">
            <span class="inline-svg">

    


    
    
    
    
    

    <svg  xmlns="http://www.w3.org/2000/svg"  width="24"  height="24"  viewBox="0 0 24 24"  fill="none"  stroke="currentColor"  stroke-width="2"  stroke-linecap="round"  stroke-linejoin="round"  class="icon icon-tabler icons-tabler-outline icon-tabler-rss"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 19m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0" /><path d="M4 4a16 16 0 0 1 16 16" /><path d="M4 11a9 9 0 0 1 9 9" /></svg>


</span>

            </a>
        </li>
    

</ul>

    </div>
    <div class="header-top-right">

    </div>
</div>


    <nav class="noselect">
        
        
        <a class="" href="http://localhost:1313/" title="">Home</a>
        
        <a class="" href="http://localhost:1313/about/" title="">About</a>
        
        <a class="" href="http://localhost:1313/tags/" title="">Tags</a>
        
        <a class="" href="http://localhost:1313/posts/" title="">Archive</a>
        
    </nav>



<script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      displayMath: [['$$','$$'], ['\\[', '\\]']],
      processEscapes: true,
      processEnvironments: true
    },
    options: {
      skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  };

  window.addEventListener('load', (event) => {
      document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>





            
        </header>
        <main id="main" tabindex="-1">
            
    

    <article class="post h-entry">
        <div class="post-header">
            <header>
                <h1 class="p-name post-title">A Journey to Reinforcement Learning</h1>
                

            </header>
            



<div class="post-info noselect">
    
        <div class="post-date dt-published">
            <time datetime="2024-07-05">2024-07-05</time>
            
        </div>
    

    <a class="post-hidden-url u-url" href="/posts/2024-07-05-rf-learning/">/posts/2024-07-05-rf-learning/</a>
    <a href="http://localhost:1313/" class="p-name p-author post-hidden-author h-card" rel="me"></a>


    <div class="post-taxonomies">
        
        
            <ul class="post-tags">
                
                    
                    <li><a href="/tags/machine-learning/">#Machine Learning</a></li>
                
                    
                    <li><a href="/tags/deep-reinforcement-learning/">#Deep Reinforcement Learning</a></li>
                
                    
                    <li><a href="/tags/reinforcement-learning/">#Reinforcement Learning</a></li>
                
            </ul>
        
        
    </div>
</div>

        </div>
        

  
  




  
  
  
  <details class="toc noselect">
    <summary>Table of Contents</summary>
    <div class="inner"><nav id="TableOfContents">
  <ul>
    <li><a href="#basic-problem-statement-of-reinforcement-learning">Basic Problem Statement of Reinforcement Learning</a></li>
    <li><a href="#model-based---when-the-environment-is-given">Model Based - When the environment is given</a>
      <ul>
        <li><a href="#dynamic-programming">Dynamic Programming</a></li>
      </ul>
    </li>
    <li><a href="#model-free---when-the-environment-is-unknown">Model Free - When the environment is unknown</a></li>
    <li><a href="#value-based">Value Based</a>
      <ul>
        <li><a href="#on-policy">On-Policy</a>
          <ul>
            <li><a href="#sarsa">SARSA</a></li>
          </ul>
        </li>
        <li><a href="#off-policy">Off-Policy</a>
          <ul>
            <li><a href="#q-learning">Q-Learning</a></li>
            <li><a href="#deep-q-network-dqn">Deep Q Network (DQN)</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#policy-based">Policy Based</a>
      <ul>
        <li><a href="#gradient-based">Gradient Based</a>
          <ul>
            <li><a href="#policy-gradient">Policy Gradient</a></li>
            <li><a href="#trpoppo">TRPO/PPO</a></li>
            <li><a href="#actor-critic-ac">Actor Critic (AC)</a></li>
          </ul>
        </li>
        <li><a href="#gradient-free">Gradient Free</a>
          <ul>
            <li><a href="#cross-entropy-method">Cross-Entropy Method</a></li>
            <li><a href="#evolution-strategy">Evolution Strategy</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#summary">Summary</a></li>
    <li><a href="#citation">Citation</a></li>
    <li><a href="#reference">Reference</a></li>
  </ul>
</nav></div>
  </details>
  



<script>
  var toc = document.querySelector(".toc");
  if (toc) {
    toc.addEventListener("click", function () {
      if (event.target.tagName !== "A") {
        event.preventDefault();
        if (this.open) {
          this.open = false;
          this.classList.remove("expanded");
        } else {
          this.open = true;
          this.classList.add("expanded");
        }
      }
    });
  }
</script>

        <div class="content e-content">
            <p align="center">
<img src="/rf/rf.png" width="600" height="400"><br>
<em>Figure 1: basic RL model</em>
<p>
<p><em>Image cited from <sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup></em></p>
<h2 id="basic-problem-statement-of-reinforcement-learning" >
<div>
    <a href="#basic-problem-statement-of-reinforcement-learning">
        
    </a>
    Basic Problem Statement of Reinforcement Learning
</div>
</h2>
<p>Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by taking actions in
an environment to maximize cumulative reward. Unlike supervised learning, where the model is trained on a fixed dataset,
RL involves learning through interaction with the environment. Let&rsquo;s define some basic elements in RL domain.</p>
<ul>
<li><strong>Agent</strong>: The learner or decision maker.</li>
<li><strong>Environment</strong>: The external system the agent interacts with.</li>
<li><strong>State</strong> $S$: A representation of the current situation of the agent.</li>
<li><strong>Action</strong> $A$: The set of all possible moves the agent can make.</li>
<li><strong>Reward</strong> $R$: A feedback signal from the environment to evaluate the agent&rsquo;s action.</li>
<li><strong>Policy $\pi$</strong>: A strategy used by the agent to determine the next action based on the current state. It&rsquo;s usually
a probability function $\pi: S\times A$ -&gt; $[0, 1]$</li>
<li><strong>Value Function $V(s)$</strong>: A function that estimates the expected cumulative reward from a given state.</li>
<li><strong>Q-Function $Q(s, a)$</strong>: A function that estimates the expected cumulative reward from a given state-action pair.</li>
</ul>
<p>As it can be seen in <em>Figure 1</em>, the general workflow of RL involves</p>
<ol>
<li>Observe the state $s_t$ (and reward $r_t$), the state can be any representation of the current situation or context in which the agent operates.
Note that the state space $S$ can be either <strong>finite</strong> or <strong>infinite</strong>.</li>
<li>Based on the current policy $\pi$, the agent selects an action $a_t \in A$ to perform. The selection can be <strong>deterministic</strong>
or <strong>stochastic</strong> depending on the policy.</li>
<li>The agent performs the selected action $a_t$ in the environment (can also be either <strong>known</strong> or <strong>unknown</strong>).</li>
<li>After performing the action, the agent receives a reward $r_{t+1}$ from the environment and observes the next state $s_{t+1}$.</li>
<li>The agent updates its <strong>policy</strong> $\pi(a_t|s_t)$ and <strong>value functions</strong> $V(s_t)$ or $Q(s_t, a_t)$ based on the observed reward $r_t$
and next state $s_{t+1}$. The update rule varies depending on the RL algorithm used. (Note that the policy learned in step 5
can be either the <strong>same (on policy)</strong> or <strong>different (off policy)</strong> with the ones in step 2)</li>
<li>The agent repeats again from step 1 and continues this iterative process until the policy converges, meaning it has
learned an optimal or near-optimal policy that maximizes cumulative rewards over time.</li>
</ol>
<p>Reinforcement Learning (RL) derives its name from the concept of &ldquo;reinforcement&rdquo; in behavioral psychology, where learning
occurs through rewards and punishments. The agent learns to make decisions by receiving feedback in the form of rewards or
penalties. Positive outcomes reinforce the actions that led to them, strengthening the behavior. The learning process is kind
of a process of <strong>&ldquo;Trial and Error&rdquo;</strong>, where the agent explores different actions to discover which ones yield the highest rewards.
Long-term beneficial actions are reinforced through repeated positive outcomes.</p>
<p>Now let&rsquo;s start with the most influential and fundamental RL model - Markov Decision Process (MDP). Our fantastic journey begins here.</p>
<h2 id="model-based---when-the-environment-is-given" >
<div>
    <a href="#model-based---when-the-environment-is-given">
        
    </a>
    Model Based - When the environment is given
</div>
</h2>
<h3 id="dynamic-programming" >
<div>
    <a href="#dynamic-programming">
        
    </a>
    Dynamic Programming
</div>
</h3>
<h2 id="model-free---when-the-environment-is-unknown" >
<div>
    <a href="#model-free---when-the-environment-is-unknown">
        
    </a>
    Model Free - When the environment is unknown
</div>
</h2>
<h2 id="value-based" >
<div>
    <a href="#value-based">
        
    </a>
    Value Based
</div>
</h2>
<h3 id="on-policy" >
<div>
    <a href="#on-policy">
        
    </a>
    On-Policy
</div>
</h3>
<h4 id="sarsa" >
<div>
    <a href="#sarsa">
        
    </a>
    SARSA
</div>
</h4>
<h3 id="off-policy" >
<div>
    <a href="#off-policy">
        
    </a>
    Off-Policy
</div>
</h3>
<h4 id="q-learning" >
<div>
    <a href="#q-learning">
        
    </a>
    Q-Learning
</div>
</h4>
<h4 id="deep-q-network-dqn" >
<div>
    <a href="#deep-q-network-dqn">
        
    </a>
    Deep Q Network (DQN)
</div>
</h4>
<h2 id="policy-based" >
<div>
    <a href="#policy-based">
        
    </a>
    Policy Based
</div>
</h2>
<h3 id="gradient-based" >
<div>
    <a href="#gradient-based">
        
    </a>
    Gradient Based
</div>
</h3>
<h4 id="policy-gradient" >
<div>
    <a href="#policy-gradient">
        
    </a>
    Policy Gradient
</div>
</h4>
<h4 id="trpoppo" >
<div>
    <a href="#trpoppo">
        
    </a>
    TRPO/PPO
</div>
</h4>
<h4 id="actor-critic-ac" >
<div>
    <a href="#actor-critic-ac">
        
    </a>
    Actor Critic (AC)
</div>
</h4>
<h3 id="gradient-free" >
<div>
    <a href="#gradient-free">
        
    </a>
    Gradient Free
</div>
</h3>
<h4 id="cross-entropy-method" >
<div>
    <a href="#cross-entropy-method">
        
    </a>
    Cross-Entropy Method
</div>
</h4>
<h4 id="evolution-strategy" >
<div>
    <a href="#evolution-strategy">
        
    </a>
    Evolution Strategy
</div>
</h4>
<h2 id="summary" >
<div>
    <a href="#summary">
        
    </a>
    Summary
</div>
</h2>
<h2 id="citation" >
<div>
    <a href="#citation">
        
    </a>
    Citation
</div>
</h2>
<h2 id="reference" >
<div>
    <a href="#reference">
        
    </a>
    Reference
</div>
</h2>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://www.mdpi.com/2076-3417/13/4/2443">Souchleris, Konstantinos, George K. Sidiropoulos, and George A. Papakostas. &ldquo;Reinforcement learning in game industry—review, prospects and challenges.&rdquo; Applied Sciences 13.4 (2023): 2443</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>
        </div>

    </article>

    
    
        
    

    
        
        
            <h3 class="read-next-title noselect">Read next</h3>
            <ul class="read-next-posts noselect">
                
                <li><a href="/posts/2024-06-06-recommendation-model/">Recommendation Models</a></li>
                
            </ul>
        
    

    

    
        








            

<script>
        function detectCurrentScheme2() {
                const defaultTheme = "auto";
                if (localStorage !== null && localStorage.getItem("user-color-scheme")) {
                        return localStorage.getItem("user-color-scheme");
                }
                if (defaultTheme === "dark" || defaultTheme === "light") {
                        return defaultTheme;
                }
                return window.matchMedia("(prefers-color-scheme: dark)").matches ? "dark" : "light";
        }

        let giscusTheme = detectCurrentScheme2();
        let giscusAttributes = {
                src: "https://giscus.app/client.js",
                "data-repo": "Bingzw\/bingzw.github.io",
                "data-repo-id": "R_kgDOMB8LQg",
                "data-category": "Announcements",
                "data-category-id": "DIC_kwDOMB8LQs4CfrMr",
                "data-mapping": "pathname",
                "data-strict": "0",
                "data-reactions-enabled": "1",
                "data-emit-metadata": "0",
                "data-input-position": "bottom",
                "data-theme": giscusTheme,
                "data-lang": "en",
                crossorigin: "anonymous",
                lazyload: "false",
                async: true,
        };
        let main = document.querySelector("main");
        let giscusScript = document.createElement("script");
        Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
        main.appendChild(giscusScript);
</script>




    

    

    

        </main>
        
            <footer class="common-footer noselect">
    
    

    <div class="common-footer-bottom">
        

        <div style="display: flex; align-items: center; gap:8px">
            © Bing Wang, 2024
            
        </div>
        <div style="display:flex;align-items: center">
            
            
            
            
            
            
        </div>
        <div>
            Powered by <a target="_blank" rel="noopener noreferrer" href="https://gohugo.io/">Hugo</a>, theme <a target="_blank" rel="noopener noreferrer" href="https://github.com/Junyi-99/hugo-theme-anubis2">Anubis2</a>.<br>
            

        </div>
    </div>

    <p class="h-card vcard">

    <a href=http://localhost:1313/ class="p-name u-url url fn" rel="me"></a>

    

    
</p>

</footer>

        
    </div>
</body>
</html>
